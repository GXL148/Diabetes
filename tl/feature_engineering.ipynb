{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from util import read_data, save, plt_encoding_error, error, normal\n",
    "import matplotlib.pyplot as plt\n",
    "from Feature import Feature\n",
    "from Smote import Smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, test_A, _ = read_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_train = len(train)\n",
    "num_test_A = len(test_A)\n",
    "\n",
    "train_m = pd.concat([train, test_A])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_y = train['血糖']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = Feature(train_m)\n",
    "feature.drop_feature(['id','体检日期', '性别'])\n",
    "feature.long_tail()\n",
    "feature.fix_missing()\n",
    "feature.statistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = Feature(train_m)\n",
    "feature.statistics()\n",
    "feature.long_tail()\n",
    "drop_list = ['id', '性别','体检日期', '乙肝表面抗原','乙肝表面抗体','乙肝e抗原','乙肝e抗体','乙肝核心抗体']\n",
    "feature.drop_feature(drop_list)\n",
    "train_m = feature.get_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_columns',100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kyle\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# 重新切分训练与测试数据\n",
    "train_x = train_m.iloc[:num_train]\n",
    "test_A_new = train_m.iloc[num_train:num_test_A + num_train]\n",
    "# train_x = train_x[train_x['血糖']<=10]\n",
    "# train_y = train_y[train_x['血糖']<=10]\n",
    "train_x.drop(['血糖'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 过采样\n",
    "# glucose_index = np.where(train_m.columns == '血糖')\n",
    "# large_glucose = train_m[train_m['血糖'] > 10].index\n",
    "# train_large_glucose = train_m.iloc[large_glucose]\n",
    "# train_x_matrix = train_large_glucose.as_matrix()\n",
    "# s = Smote(train_x_matrix, N=200)\n",
    "# over_sampling_train = s.over_sampling()\n",
    "# print(over_sampling_train.shape)\n",
    "\n",
    "# over_y = over_sampling_train[:,glucose_index]\n",
    "# over_y = over_y.reshape(len(over_y))\n",
    "# over_sampling_train = np.delete(over_sampling_train, glucose_index, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = train_x.columns.tolist()\n",
    "train_X = train_x.as_matrix()\n",
    "# train_X = np.vstack((train_X, over_sampling_train))\n",
    "train_Y = train_y.as_matrix()\n",
    "# train_Y = np.hstack((train_Y, over_y))\n",
    "test_X = test_A_new.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_X, train_Y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = dict(num_leaves=[17,31,48],\n",
    "                  n_estimators=[250, 200],\n",
    "                  learning_rate=[0.01, 0.02,0.03],\n",
    "                  min_child_samples=[10, 20, 40],\n",
    "                  subsample=[0.8],\n",
    "                  reg_lambda=[0.0, 0.2, 0.4])\n",
    "lgb_regressor = lgb.LGBMRegressor(\n",
    "                  objective='regression',\n",
    "#                   min_child_samples=20,\n",
    "                  subsample_freq=1,\n",
    "                  colsample_bytree=1.0,\n",
    "                  reg_alpha=1.0,\n",
    "                  n_jobs=-1)\n",
    "grid = GridSearchCV(cv=5, estimator=lgb_regressor, n_jobs=4, param_grid=param_grid, scoring='neg_mean_squared_error')\n",
    "grid.fit(train_X, train_Y)\n",
    "print('Best parameters found by grid search are:', grid.best_params_, '  best_score: ', grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# result = grid.predict(test_X)\n",
    "# data1 = pd.DataFrame(result)\n",
    "# save(data1, 'lgb_grid_cv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'boosting': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': 'mse',\n",
    "    'num_leaves': 31,\n",
    "    'min_data_in_leaf': 20,\n",
    "    'learning_rate': 0.02,\n",
    "    'lambda_l1':1,\n",
    "    'lambda_l2':0.2,\n",
    "    'cat_smooth':10,\n",
    "    'feature_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/2 Mean squared error: 0.658585\n",
      "1/2 Mean squared error: 1.526716\n",
      "1/2 Mean squared error: 0.828925\n",
      "1/2 Mean squared error: 0.616131\n",
      "1/2 Mean squared error: 1.267448\n",
      "0.979561096676\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import lightgbm as lgb\n",
    "def cv_estimate(n_splits, lgb, train_X, train_Y, online=False):\n",
    "    test_preds = np.zeros((test_X.shape[0], n_splits))\n",
    "    cv = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    val_scores = 0\n",
    "    i = 0\n",
    "    for train, test in cv.split(train_X, train_Y):\n",
    "        train_x_k, train_y_k= train_X[train], train_Y[train]                \n",
    "        test_x_k, test_y_k = train_X[test], train_Y[test]\n",
    "        \n",
    "        lgb_train = lgb.Dataset(train_x_k, train_y_k, feature_name = features)\n",
    "        lgb_test = lgb.Dataset(test_x_k, test_y_k)\n",
    "         \n",
    "        gbm = lgb.train(params,\n",
    "                    lgb_train,\n",
    "                    num_boost_round=300)\n",
    "        y = gbm.predict(test_x_k, num_iteration=gbm.best_iteration)\n",
    "        val_scores += error(y, test_y_k)\n",
    "        \n",
    "        test_preds[:,i] = gbm.predict(test_X)\n",
    "        i += 1\n",
    "    val_scores /= n_splits\n",
    "    if online:\n",
    "        submission = pd.DataFrame({'pred':test_preds.mean(axis=1)})\n",
    "        save(submission, 'lgb_kfold')\n",
    "    return val_scores\n",
    "scores = cv_estimate(5, lgb, train_X, train_Y, online=False)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "[1]\tvalid_0's l2: 2.09944\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "[2]\tvalid_0's l2: 2.09039\n",
      "[3]\tvalid_0's l2: 2.07963\n",
      "[4]\tvalid_0's l2: 2.07003\n",
      "[5]\tvalid_0's l2: 2.05897\n",
      "[6]\tvalid_0's l2: 2.05142\n",
      "[7]\tvalid_0's l2: 2.0423\n",
      "[8]\tvalid_0's l2: 2.03578\n",
      "[9]\tvalid_0's l2: 2.0264\n",
      "[10]\tvalid_0's l2: 2.01944\n",
      "[11]\tvalid_0's l2: 2.01061\n",
      "[12]\tvalid_0's l2: 2.00487\n",
      "[13]\tvalid_0's l2: 1.99463\n",
      "[14]\tvalid_0's l2: 1.98666\n",
      "[15]\tvalid_0's l2: 1.9788\n",
      "[16]\tvalid_0's l2: 1.97251\n",
      "[17]\tvalid_0's l2: 1.96592\n",
      "[18]\tvalid_0's l2: 1.95893\n",
      "[19]\tvalid_0's l2: 1.95264\n",
      "[20]\tvalid_0's l2: 1.94714\n",
      "[21]\tvalid_0's l2: 1.93878\n",
      "[22]\tvalid_0's l2: 1.93205\n",
      "[23]\tvalid_0's l2: 1.92828\n",
      "[24]\tvalid_0's l2: 1.92291\n",
      "[25]\tvalid_0's l2: 1.91652\n",
      "[26]\tvalid_0's l2: 1.90922\n",
      "[27]\tvalid_0's l2: 1.90343\n",
      "[28]\tvalid_0's l2: 1.89741\n",
      "[29]\tvalid_0's l2: 1.89392\n",
      "[30]\tvalid_0's l2: 1.88873\n",
      "[31]\tvalid_0's l2: 1.88318\n",
      "[32]\tvalid_0's l2: 1.87801\n",
      "[33]\tvalid_0's l2: 1.87168\n",
      "[34]\tvalid_0's l2: 1.86687\n",
      "[35]\tvalid_0's l2: 1.86251\n",
      "[36]\tvalid_0's l2: 1.85853\n",
      "[37]\tvalid_0's l2: 1.85483\n",
      "[38]\tvalid_0's l2: 1.85154\n",
      "[39]\tvalid_0's l2: 1.84652\n",
      "[40]\tvalid_0's l2: 1.84412\n",
      "[41]\tvalid_0's l2: 1.84003\n",
      "[42]\tvalid_0's l2: 1.83627\n",
      "[43]\tvalid_0's l2: 1.83426\n",
      "[44]\tvalid_0's l2: 1.82973\n",
      "[45]\tvalid_0's l2: 1.82812\n",
      "[46]\tvalid_0's l2: 1.82488\n",
      "[47]\tvalid_0's l2: 1.82241\n",
      "[48]\tvalid_0's l2: 1.82052\n",
      "[49]\tvalid_0's l2: 1.8177\n",
      "[50]\tvalid_0's l2: 1.81428\n",
      "[51]\tvalid_0's l2: 1.8133\n",
      "[52]\tvalid_0's l2: 1.81061\n",
      "[53]\tvalid_0's l2: 1.80886\n",
      "[54]\tvalid_0's l2: 1.80733\n",
      "[55]\tvalid_0's l2: 1.80339\n",
      "[56]\tvalid_0's l2: 1.80079\n",
      "[57]\tvalid_0's l2: 1.79851\n",
      "[58]\tvalid_0's l2: 1.79794\n",
      "[59]\tvalid_0's l2: 1.79483\n",
      "[60]\tvalid_0's l2: 1.79158\n",
      "[61]\tvalid_0's l2: 1.79116\n",
      "[62]\tvalid_0's l2: 1.7886\n",
      "[63]\tvalid_0's l2: 1.78635\n",
      "[64]\tvalid_0's l2: 1.78433\n",
      "[65]\tvalid_0's l2: 1.78145\n",
      "[66]\tvalid_0's l2: 1.77956\n",
      "[67]\tvalid_0's l2: 1.77705\n",
      "[68]\tvalid_0's l2: 1.77584\n",
      "[69]\tvalid_0's l2: 1.77414\n",
      "[70]\tvalid_0's l2: 1.77287\n",
      "[71]\tvalid_0's l2: 1.76982\n",
      "[72]\tvalid_0's l2: 1.76852\n",
      "[73]\tvalid_0's l2: 1.76597\n",
      "[74]\tvalid_0's l2: 1.76492\n",
      "[75]\tvalid_0's l2: 1.76335\n",
      "[76]\tvalid_0's l2: 1.76174\n",
      "[77]\tvalid_0's l2: 1.76043\n",
      "[78]\tvalid_0's l2: 1.75834\n",
      "[79]\tvalid_0's l2: 1.75702\n",
      "[80]\tvalid_0's l2: 1.75606\n",
      "[81]\tvalid_0's l2: 1.75481\n",
      "[82]\tvalid_0's l2: 1.75338\n",
      "[83]\tvalid_0's l2: 1.75096\n",
      "[84]\tvalid_0's l2: 1.74844\n",
      "[85]\tvalid_0's l2: 1.7481\n",
      "[86]\tvalid_0's l2: 1.74577\n",
      "[87]\tvalid_0's l2: 1.74386\n",
      "[88]\tvalid_0's l2: 1.74299\n",
      "[89]\tvalid_0's l2: 1.7417\n",
      "[90]\tvalid_0's l2: 1.73998\n",
      "[91]\tvalid_0's l2: 1.73886\n",
      "[92]\tvalid_0's l2: 1.73883\n",
      "[93]\tvalid_0's l2: 1.73709\n",
      "[94]\tvalid_0's l2: 1.73602\n",
      "[95]\tvalid_0's l2: 1.73605\n",
      "[96]\tvalid_0's l2: 1.73545\n",
      "[97]\tvalid_0's l2: 1.73509\n",
      "[98]\tvalid_0's l2: 1.73311\n",
      "[99]\tvalid_0's l2: 1.73178\n",
      "[100]\tvalid_0's l2: 1.73049\n",
      "[101]\tvalid_0's l2: 1.73\n",
      "[102]\tvalid_0's l2: 1.72855\n",
      "[103]\tvalid_0's l2: 1.72811\n",
      "[104]\tvalid_0's l2: 1.72781\n",
      "[105]\tvalid_0's l2: 1.72691\n",
      "[106]\tvalid_0's l2: 1.72466\n",
      "[107]\tvalid_0's l2: 1.72375\n",
      "[108]\tvalid_0's l2: 1.72441\n",
      "[109]\tvalid_0's l2: 1.7226\n",
      "[110]\tvalid_0's l2: 1.72194\n",
      "[111]\tvalid_0's l2: 1.7204\n",
      "[112]\tvalid_0's l2: 1.71917\n",
      "[113]\tvalid_0's l2: 1.71828\n",
      "[114]\tvalid_0's l2: 1.71743\n",
      "[115]\tvalid_0's l2: 1.71606\n",
      "[116]\tvalid_0's l2: 1.71586\n",
      "[117]\tvalid_0's l2: 1.71528\n",
      "[118]\tvalid_0's l2: 1.71469\n",
      "[119]\tvalid_0's l2: 1.71417\n",
      "[120]\tvalid_0's l2: 1.7131\n",
      "[121]\tvalid_0's l2: 1.71178\n",
      "[122]\tvalid_0's l2: 1.71176\n",
      "[123]\tvalid_0's l2: 1.7107\n",
      "[124]\tvalid_0's l2: 1.70936\n",
      "[125]\tvalid_0's l2: 1.70933\n",
      "[126]\tvalid_0's l2: 1.70962\n",
      "[127]\tvalid_0's l2: 1.70915\n",
      "[128]\tvalid_0's l2: 1.70889\n",
      "[129]\tvalid_0's l2: 1.70908\n",
      "[130]\tvalid_0's l2: 1.70881\n",
      "[131]\tvalid_0's l2: 1.7088\n",
      "[132]\tvalid_0's l2: 1.70795\n",
      "[133]\tvalid_0's l2: 1.70796\n",
      "[134]\tvalid_0's l2: 1.70809\n",
      "[135]\tvalid_0's l2: 1.70878\n",
      "[136]\tvalid_0's l2: 1.70847\n",
      "[137]\tvalid_0's l2: 1.70906\n",
      "[138]\tvalid_0's l2: 1.70794\n",
      "[139]\tvalid_0's l2: 1.70872\n",
      "[140]\tvalid_0's l2: 1.70915\n",
      "[141]\tvalid_0's l2: 1.70997\n",
      "[142]\tvalid_0's l2: 1.70999\n",
      "[143]\tvalid_0's l2: 1.70904\n",
      "[144]\tvalid_0's l2: 1.70932\n",
      "[145]\tvalid_0's l2: 1.70919\n",
      "[146]\tvalid_0's l2: 1.70837\n",
      "[147]\tvalid_0's l2: 1.70754\n",
      "[148]\tvalid_0's l2: 1.7081\n",
      "[149]\tvalid_0's l2: 1.70619\n",
      "[150]\tvalid_0's l2: 1.70649\n",
      "[151]\tvalid_0's l2: 1.70725\n",
      "[152]\tvalid_0's l2: 1.70756\n",
      "[153]\tvalid_0's l2: 1.70731\n",
      "[154]\tvalid_0's l2: 1.70722\n",
      "[155]\tvalid_0's l2: 1.70793\n",
      "[156]\tvalid_0's l2: 1.70885\n",
      "[157]\tvalid_0's l2: 1.70845\n",
      "[158]\tvalid_0's l2: 1.70793\n",
      "[159]\tvalid_0's l2: 1.70694\n",
      "[160]\tvalid_0's l2: 1.70653\n",
      "[161]\tvalid_0's l2: 1.70635\n",
      "[162]\tvalid_0's l2: 1.70602\n",
      "[163]\tvalid_0's l2: 1.70598\n",
      "[164]\tvalid_0's l2: 1.70659\n",
      "[165]\tvalid_0's l2: 1.7064\n",
      "[166]\tvalid_0's l2: 1.70626\n",
      "[167]\tvalid_0's l2: 1.70585\n",
      "[168]\tvalid_0's l2: 1.70637\n",
      "[169]\tvalid_0's l2: 1.70497\n",
      "[170]\tvalid_0's l2: 1.7054\n",
      "[171]\tvalid_0's l2: 1.70516\n",
      "[172]\tvalid_0's l2: 1.70457\n",
      "[173]\tvalid_0's l2: 1.70329\n",
      "[174]\tvalid_0's l2: 1.7026\n",
      "[175]\tvalid_0's l2: 1.70247\n",
      "[176]\tvalid_0's l2: 1.7021\n",
      "[177]\tvalid_0's l2: 1.70291\n",
      "[178]\tvalid_0's l2: 1.70212\n",
      "[179]\tvalid_0's l2: 1.70199\n",
      "[180]\tvalid_0's l2: 1.70251\n",
      "[181]\tvalid_0's l2: 1.70291\n",
      "[182]\tvalid_0's l2: 1.70242\n",
      "[183]\tvalid_0's l2: 1.70226\n",
      "[184]\tvalid_0's l2: 1.70302\n",
      "[185]\tvalid_0's l2: 1.70226\n",
      "[186]\tvalid_0's l2: 1.70288\n",
      "[187]\tvalid_0's l2: 1.70296\n",
      "[188]\tvalid_0's l2: 1.70228\n",
      "[189]\tvalid_0's l2: 1.7023\n",
      "[190]\tvalid_0's l2: 1.70253\n",
      "[191]\tvalid_0's l2: 1.70316\n",
      "[192]\tvalid_0's l2: 1.70303\n",
      "[193]\tvalid_0's l2: 1.70386\n",
      "[194]\tvalid_0's l2: 1.7049\n",
      "[195]\tvalid_0's l2: 1.70371\n",
      "[196]\tvalid_0's l2: 1.7035\n",
      "[197]\tvalid_0's l2: 1.70288\n",
      "[198]\tvalid_0's l2: 1.70204\n",
      "[199]\tvalid_0's l2: 1.70195\n",
      "[200]\tvalid_0's l2: 1.70164\n",
      "[201]\tvalid_0's l2: 1.70192\n",
      "[202]\tvalid_0's l2: 1.7015\n",
      "[203]\tvalid_0's l2: 1.70218\n",
      "[204]\tvalid_0's l2: 1.702\n",
      "[205]\tvalid_0's l2: 1.70211\n",
      "[206]\tvalid_0's l2: 1.70257\n",
      "[207]\tvalid_0's l2: 1.70255\n",
      "[208]\tvalid_0's l2: 1.70154\n",
      "[209]\tvalid_0's l2: 1.70162\n",
      "[210]\tvalid_0's l2: 1.7007\n",
      "[211]\tvalid_0's l2: 1.70075\n",
      "[212]\tvalid_0's l2: 1.70062\n",
      "[213]\tvalid_0's l2: 1.7009\n",
      "[214]\tvalid_0's l2: 1.69995\n",
      "[215]\tvalid_0's l2: 1.69924\n",
      "[216]\tvalid_0's l2: 1.69893\n",
      "[217]\tvalid_0's l2: 1.69879\n",
      "[218]\tvalid_0's l2: 1.69905\n",
      "[219]\tvalid_0's l2: 1.6995\n",
      "[220]\tvalid_0's l2: 1.6997\n",
      "[221]\tvalid_0's l2: 1.69884\n",
      "[222]\tvalid_0's l2: 1.69896\n",
      "[223]\tvalid_0's l2: 1.69835\n",
      "[224]\tvalid_0's l2: 1.69736\n",
      "[225]\tvalid_0's l2: 1.69779\n",
      "[226]\tvalid_0's l2: 1.69735\n",
      "[227]\tvalid_0's l2: 1.698\n",
      "[228]\tvalid_0's l2: 1.6987\n",
      "[229]\tvalid_0's l2: 1.69873\n",
      "[230]\tvalid_0's l2: 1.69789\n",
      "[231]\tvalid_0's l2: 1.69843\n",
      "[232]\tvalid_0's l2: 1.69824\n",
      "[233]\tvalid_0's l2: 1.69819\n",
      "[234]\tvalid_0's l2: 1.69759\n",
      "[235]\tvalid_0's l2: 1.69771\n",
      "[236]\tvalid_0's l2: 1.69693\n",
      "[237]\tvalid_0's l2: 1.69652\n",
      "[238]\tvalid_0's l2: 1.69608\n",
      "[239]\tvalid_0's l2: 1.69592\n",
      "[240]\tvalid_0's l2: 1.69567\n",
      "[241]\tvalid_0's l2: 1.69569\n",
      "[242]\tvalid_0's l2: 1.6961\n",
      "[243]\tvalid_0's l2: 1.69608\n",
      "[244]\tvalid_0's l2: 1.69599\n",
      "[245]\tvalid_0's l2: 1.69654\n",
      "[246]\tvalid_0's l2: 1.69678\n",
      "[247]\tvalid_0's l2: 1.69681\n",
      "[248]\tvalid_0's l2: 1.69709\n",
      "[249]\tvalid_0's l2: 1.69693\n",
      "[250]\tvalid_0's l2: 1.69715\n",
      "[251]\tvalid_0's l2: 1.69771\n",
      "[252]\tvalid_0's l2: 1.69802\n",
      "[253]\tvalid_0's l2: 1.69755\n",
      "[254]\tvalid_0's l2: 1.69682\n",
      "[255]\tvalid_0's l2: 1.69575\n",
      "[256]\tvalid_0's l2: 1.69604\n",
      "[257]\tvalid_0's l2: 1.69516\n",
      "[258]\tvalid_0's l2: 1.6955\n",
      "[259]\tvalid_0's l2: 1.69547\n",
      "[260]\tvalid_0's l2: 1.69511\n",
      "[261]\tvalid_0's l2: 1.69458\n",
      "[262]\tvalid_0's l2: 1.69544\n",
      "[263]\tvalid_0's l2: 1.69633\n",
      "[264]\tvalid_0's l2: 1.69627\n",
      "[265]\tvalid_0's l2: 1.69615\n",
      "[266]\tvalid_0's l2: 1.69543\n",
      "[267]\tvalid_0's l2: 1.6952\n",
      "[268]\tvalid_0's l2: 1.69484\n",
      "[269]\tvalid_0's l2: 1.69491\n",
      "[270]\tvalid_0's l2: 1.69497\n",
      "[271]\tvalid_0's l2: 1.69519\n",
      "[272]\tvalid_0's l2: 1.69525\n",
      "[273]\tvalid_0's l2: 1.69579\n",
      "[274]\tvalid_0's l2: 1.69653\n",
      "[275]\tvalid_0's l2: 1.69649\n",
      "[276]\tvalid_0's l2: 1.69593\n",
      "[277]\tvalid_0's l2: 1.69598\n",
      "[278]\tvalid_0's l2: 1.6967\n",
      "[279]\tvalid_0's l2: 1.69676\n",
      "[280]\tvalid_0's l2: 1.69663\n",
      "[281]\tvalid_0's l2: 1.69605\n",
      "Early stopping, best iteration is:\n",
      "[261]\tvalid_0's l2: 1.69458\n",
      "Start predicting...\n",
      "1/2 Mean squared error: 0.847290\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# create dataset for lightgbm\n",
    "lgb_train = lgb.Dataset(X_train, y_train, feature_name = features)\n",
    "lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train, feature_name = features)\n",
    "\n",
    "train_all = lgb.Dataset(train_X, train_Y, feature_name = features)\n",
    "\n",
    "# specify your configurations as a dict\n",
    "\n",
    "print('Start training...')\n",
    "# train\n",
    "gbm = lgb.train(params,\n",
    "                   lgb_train,\n",
    "                    num_boost_round=283,\n",
    "                    valid_sets=lgb_eval,\n",
    "                    early_stopping_rounds=20)\n",
    "\n",
    "print('Start predicting...')\n",
    "# predict\n",
    "y_pred = gbm.predict(X_test, num_iteration=gbm.best_iteration)\n",
    "# eval\n",
    "error(y_test, y_pred)\n",
    "\n",
    "# online\n",
    "\n",
    "predict = gbm.predict(test_X, num_iteration=gbm.best_iteration)\n",
    "data1 = pd.DataFrame(predict)\n",
    "# save\n",
    "# save(data1, 'lgb')\n",
    "\n",
    "# gbm_online = lgb.train(params,\n",
    "#                 train_all,\n",
    "#                 num_boost_round=280)\n",
    "# # predict\n",
    "# predict = gbm_online.predict(test_X, num_iteration=gbm_online.best_iteration)\n",
    "# data1 = pd.DataFrame(predict)\n",
    "# # save\n",
    "# save(data1, 'lgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt_encoding_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb.plot_importance(gbm)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

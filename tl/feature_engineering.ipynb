{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from util import read_data, save, plt_encoding_error, error, normal\n",
    "import matplotlib.pyplot as plt\n",
    "from Feature import Feature\n",
    "from Smote import Smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, test_A, _ = read_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_train = len(train)\n",
    "num_test_A = len(test_A)\n",
    "\n",
    "train_m = pd.concat([train, test_A])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_columns',100)\n",
    "train_m.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_y = train['血糖']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_m['体检日期'] = pd.to_datetime(train_m['体检日期'])\n",
    "train_m['weekday'] = train_m['体检日期'].dt.weekday\n",
    "train_m.drop(['体检日期'], axis=1, inplace=True)\n",
    "train_m = pd.get_dummies(train_m, columns=['weekday'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_m.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "important_feature = ['*天门冬氨酸氨基转换酶','*丙氨酸氨基转换酶','*碱性磷酸酶','*r-谷氨酰基转换酶','*总蛋白','白蛋白','*球蛋白','白球比例','甘油三酯','总胆固醇','高密度脂蛋白胆固醇','低密度脂蛋白胆固醇','尿素','肌酐','尿酸','乙肝表面抗原','乙肝表面抗体','乙肝e抗原','乙肝e抗体','乙肝核心抗体']\n",
    "trian_imp = train.loc[:,important_feature]\n",
    "row_index = trian_imp[trian_imp.T.count()==0].index\n",
    "train_m.drop(row_index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_m.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature = Feature(train_m)\n",
    "feature.drop_feature(['id','体检日期', '性别'])\n",
    "feature.long_tail()\n",
    "feature.fix_missing()\n",
    "feature.statistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature = Feature(train_m)\n",
    "feature.statistics()\n",
    "feature.long_tail()\n",
    "drop_list = ['id', '性别','体检日期', '乙肝表面抗原','乙肝表面抗体','乙肝e抗原','乙肝e抗体','乙肝核心抗体']\n",
    "feature.drop_feature(drop_list)\n",
    "train_m = feature.get_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('max_columns',100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重新切分训练与测试数据\n",
    "train_x = train_m.iloc[:num_train]\n",
    "test_A_new = train_m.iloc[num_train:num_test_A + num_train]\n",
    "# train_x = train_x[train_x['血糖']<=10]\n",
    "# train_y = train_y[train_x['血糖']<=10]\n",
    "train_x.drop(['血糖'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 过采样\n",
    "# glucose_index = np.where(train_m.columns == '血糖')\n",
    "# large_glucose = train_m[train_m['血糖'] > 10].index\n",
    "# train_large_glucose = train_m.iloc[large_glucose]\n",
    "# train_x_matrix = train_large_glucose.as_matrix()\n",
    "# s = Smote(train_x_matrix, N=200)\n",
    "# over_sampling_train = s.over_sampling()\n",
    "# print(over_sampling_train.shape)\n",
    "\n",
    "# over_y = over_sampling_train[:,glucose_index]\n",
    "# over_y = over_y.reshape(len(over_y))\n",
    "# over_sampling_train = np.delete(over_sampling_train, glucose_index, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = train_x.columns.tolist()\n",
    "train_X = train_x.as_matrix()\n",
    "# train_X = np.vstack((train_X, over_sampling_train))\n",
    "train_Y = train_y.as_matrix()\n",
    "# train_Y = np.hstack((train_Y, over_y))\n",
    "test_X = test_A_new.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_X, train_Y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = dict(num_leaves=[17,31,48],\n",
    "                  n_estimators=[250, 200],\n",
    "                  learning_rate=[0.01, 0.02,0.03],\n",
    "                  min_child_samples=[10, 20, 40],\n",
    "                  subsample=[0.8],\n",
    "                  reg_lambda=[0.0, 0.2, 0.4])\n",
    "lgb_regressor = lgb.LGBMRegressor(\n",
    "                  objective='regression',\n",
    "#                   min_child_samples=20,\n",
    "                  subsample_freq=1,\n",
    "                  colsample_bytree=1.0,\n",
    "                  reg_alpha=1.0,\n",
    "                  n_jobs=-1)\n",
    "grid = GridSearchCV(cv=5, estimator=lgb_regressor, n_jobs=4, param_grid=param_grid, scoring='neg_mean_squared_error')\n",
    "grid.fit(train_X, train_Y)\n",
    "print('Best parameters found by grid search are:', grid.best_params_, '  best_score: ', grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# result = grid.predict(test_X)\n",
    "# data1 = pd.DataFrame(result)\n",
    "# save(data1, 'lgb_grid_cv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'boosting': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': 'mse',\n",
    "    'num_leaves': 31,\n",
    "    'min_data_in_leaf': 20,\n",
    "    'learning_rate': 0.02,\n",
    "    'lambda_l1':1,\n",
    "    'lambda_l2':0.2,\n",
    "    'cat_smooth':10,\n",
    "    'feature_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import lightgbm as lgb\n",
    "def cv_estimate(n_splits, lgb, train_X, train_Y, online=False):\n",
    "    test_preds = np.zeros((test_X.shape[0], n_splits))\n",
    "    cv = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    val_scores = 0\n",
    "    i = 0\n",
    "    for train, test in cv.split(train_X, train_Y):\n",
    "        train_x_k, train_y_k= train_X[train], train_Y[train]                \n",
    "        test_x_k, test_y_k = train_X[test], train_Y[test]\n",
    "        \n",
    "        lgb_train = lgb.Dataset(train_x_k, train_y_k, feature_name = features)\n",
    "        lgb_test = lgb.Dataset(test_x_k, test_y_k)\n",
    "         \n",
    "        gbm = lgb.train(params,\n",
    "                    lgb_train,\n",
    "                    num_boost_round=300)\n",
    "        y = gbm.predict(test_x_k, num_iteration=gbm.best_iteration)\n",
    "        val_scores += error(y, test_y_k)\n",
    "        \n",
    "        test_preds[:,i] = gbm.predict(test_X)\n",
    "        i += 1\n",
    "    val_scores /= n_splits\n",
    "    if online:\n",
    "        submission = pd.DataFrame({'pred':test_preds.mean(axis=1)})\n",
    "        save(submission, 'lgb_kfold')\n",
    "    return val_scores\n",
    "scores = cv_estimate(5, lgb, train_X, train_Y, online=False)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# create dataset for lightgbm\n",
    "lgb_train = lgb.Dataset(X_train, y_train, feature_name = features)\n",
    "lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train, feature_name = features)\n",
    "\n",
    "train_all = lgb.Dataset(train_X, train_Y, feature_name = features)\n",
    "\n",
    "# specify your configurations as a dict\n",
    "\n",
    "print('Start training...')\n",
    "# train\n",
    "gbm = lgb.train(params,\n",
    "                   lgb_train,\n",
    "                    num_boost_round=283,\n",
    "                    valid_sets=lgb_eval,\n",
    "                    early_stopping_rounds=20)\n",
    "\n",
    "print('Start predicting...')\n",
    "# predict\n",
    "y_pred = gbm.predict(X_test, num_iteration=gbm.best_iteration)\n",
    "# eval\n",
    "error(y_test, y_pred)\n",
    "\n",
    "# online\n",
    "\n",
    "predict = gbm.predict(test_X, num_iteration=gbm.best_iteration)\n",
    "data1 = pd.DataFrame(predict)\n",
    "# save\n",
    "# save(data1, 'lgb')\n",
    "\n",
    "# gbm_online = lgb.train(params,\n",
    "#                 train_all,\n",
    "#                 num_boost_round=280)\n",
    "# # predict\n",
    "# predict = gbm_online.predict(test_X, num_iteration=gbm_online.best_iteration)\n",
    "# data1 = pd.DataFrame(predict)\n",
    "# # save\n",
    "# save(data1, 'lgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt_encoding_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lgb.plot_importance(gbm)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.linear_model import ElasticNetCV, RidgeCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.pipeline import make_pipeline, make_union, Pipeline\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVR,SVC\n",
    "from sklearn.linear_model import LinearRegression, ElasticNet,Ridge,Lasso,RidgeClassifierCV,LogisticRegression\n",
    "from sklearn.model_selection import KFold  \n",
    "from sklearn.feature_selection import SelectPercentile, f_regression\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import copy as cp\n",
    "from sklearn.preprocessing import MaxAbsScaler, Normalizer\n",
    "from sklearn.svm import LinearSVR\n",
    "from tpot.builtins import StackingEstimator\n",
    "from imblearn.under_sampling import NearMiss ,RandomUnderSampler, NeighbourhoodCleaningRule, OneSidedSelection, AllKNN\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from xgboost import XGBRegressor\n",
    "from imblearn.ensemble import EasyEnsemble \n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.utils import shuffle\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from imblearn.ensemble import BalancedBaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../data/processed/train.csv\")\n",
    "test = pd.read_csv(\"../data/processed/test.csv\")\n",
    "train.pop(\"id\")\n",
    "test.pop(\"id\")\n",
    "target = train.pop(\"血糖\")\n",
    "\n",
    "train_x= train.as_matrix()\n",
    "train_y = target.as_matrix()\n",
    "test_x = test.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "high_labels = np.zeros((train_y.shape[0],))\n",
    "for i in range(train_y.shape[0]):\n",
    "    if train_y[i]<10:\n",
    "        high_labels[i] = 1\n",
    "    else:\n",
    "        high_labels[i] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin, ClassifierMixin\n",
    "from sklearn.utils import check_array\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "class myStackingFeatures(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.estimator = None\n",
    "        self.lgb = lgb.LGBMClassifier(boosting_type=\"GBDT\",\n",
    "                                      num_leaves=31,\n",
    "                                      learning_rate=0.01,\n",
    "                                      feature_fraction=0.5,\n",
    "                                      bagging_fraction=0.5,\n",
    "                                      bagging_freq=5,\n",
    "                                      n_estimators=400)\n",
    "        self.grd_enc = OneHotEncoder()\n",
    "        self.lr = LogisticRegression()\n",
    "        self.classes_ = [-1,1]\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        self.lgb.fit(X, y)\n",
    "        self.grd_enc.fit(self.lgb.apply(X))\n",
    "        self.lr.fit(self.grd_enc.transform(self.lgb.apply(X)), y)\n",
    "    def predict_proba(self, X):\n",
    "        return self.lr.predict_proba(self.grd_enc.transform(self.lgb.apply(X)))\n",
    "    def predict(self, X):\n",
    "        return self.lr.predict(self.grd_enc.transform(self.lgb.apply(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def modif_value(training_features, training_target, training_labels, testing_features, X, Y):\n",
    "    exported_pipeline = classifier = Pipeline([\n",
    "            (\"scaler\",MaxAbsScaler()),\n",
    "            (\"SVR\",StackingEstimator(estimator=SVC())),\n",
    "            (\"RidgeCV\",StackingEstimator(estimator=RidgeClassifierCV())),\n",
    "            (\"BaggingClassifier\",BaggingClassifier(base_estimator=myStackingFeatures(),random_state=201801))])\n",
    "    exported_pipeline.fit(training_features, training_labels)\n",
    "    prob = exported_pipeline.predict_proba(testing_features)\n",
    "    \n",
    "    \n",
    "    predicts = np.zeros((prob.shape[0],))\n",
    "    for i in range(prob.shape[0]):\n",
    "        if prob[i,1]>0.5:\n",
    "            predicts[i] = 1\n",
    "        else:\n",
    "            predicts[i] = -1\n",
    "    negative_pred_list = list(np.where(predicts==-1)[0])\n",
    "    negative_labels_list = list(np.where(training_labels==-1)[0])\n",
    "    \n",
    "\n",
    "    \n",
    "    negative_results = None\n",
    "\n",
    "    \n",
    "    if len(negative_pred_list)==0:\n",
    "        negative_results = []\n",
    "    else:\n",
    "        exported_pipeline = Pipeline([\n",
    "            (\"scaler\", MaxAbsScaler()),\n",
    "            (\"SVR\", StackingEstimator(\n",
    "                estimator=LinearSVR(C=0.01, dual=False, epsilon=1.0, loss=\"squared_epsilon_insensitive\", tol=0.001))),\n",
    "            (\"RidgeCV\", StackingEstimator(estimator=RidgeCV())),\n",
    "            (\"LGB\", lgb.LGBMRegressor(objective='regression',\n",
    "                                      boosting_type=\"GBDT\",\n",
    "                                      num_leaves=31,\n",
    "                                      learning_rate=0.01,\n",
    "                                      feature_fraction=0.5,\n",
    "                                      bagging_fraction=0.5,\n",
    "                                      bagging_freq=5,\n",
    "                                      n_estimators=400))]\n",
    "        )\n",
    "        print(len(negative_labels_list))\n",
    "        exported_pipeline.fit(X, Y)\n",
    "        negative_results = exported_pipeline.predict(testing_features[negative_pred_list])  \n",
    "        \n",
    "    positive_pred_list = list(np.where(predicts==1)[0])\n",
    "    positive_labels_list = list(np.where(training_labels==1)[0])\n",
    "    positive_results = None\n",
    "    '''   \n",
    "    if len(positive_pred_list)==0:\n",
    "        positive_results = []\n",
    "    else:\n",
    "        exported_pipeline = Pipeline([\n",
    "            (\"scaler\", MaxAbsScaler()),\n",
    "            (\"SVR\", StackingEstimator(\n",
    "                estimator=LinearSVR(C=0.01, dual=False, epsilon=1.0, loss=\"squared_epsilon_insensitive\", tol=0.001))),\n",
    "            (\"RidgeCV\", StackingEstimator(estimator=RidgeCV())),\n",
    "            (\"LGB\", lgb.LGBMRegressor(objective='regression',\n",
    "                                      boosting_type=\"GBDT\",\n",
    "                                      num_leaves=31,\n",
    "                                      learning_rate=0.01,\n",
    "                                      feature_fraction=0.5,\n",
    "                                      bagging_fraction=0.5,\n",
    "                                      bagging_freq=5,\n",
    "                                      n_estimators=400))]\n",
    "        )\n",
    "        \n",
    "        exported_pipeline.fit(training_features[positive_labels_list], training_target[positive_labels_list])\n",
    "        positive_results = exported_pipeline.predict(testing_features[positive_pred_list])  \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    return negative_results,negative_pred_list, positive_results,positive_pred_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class myStackingFeaturesRegressor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.estimator = None\n",
    "        self.lgb = GradientBoostingRegressor(loss='ls', alpha=0.9,\n",
    "                                    n_estimators=200,\n",
    "                                    learning_rate=0.02,\n",
    "                                    max_depth=8,\n",
    "                                    subsample=0.8,\n",
    "                                    min_samples_split=9,\n",
    "                                    max_leaf_nodes=12)\n",
    "        self.grd_enc = OneHotEncoder()\n",
    "        self.lr = RidgeCV()\n",
    "        self.classes_ = [-1,1]\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        self.lgb.fit(X, y)\n",
    "        self.grd_enc.fit(self.lgb.apply(X))\n",
    "        self.lr.fit(self.grd_enc.transform(self.lgb.apply(X)), y)\n",
    "    def predict(self, X):\n",
    "        return self.lr.predict(self.grd_enc.transform(self.lgb.apply(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\altman\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:642: UserWarning: max_bin keyword has been found in `params` and will be ignored. Please use max_bin argument of the Dataset constructor to pass this parameter.\n",
      "  'Please use {0} argument of the Dataset constructor to pass this parameter.'.format(key))\n",
      "C:\\Users\\altman\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:648: LGBMDeprecationWarning: The `max_bin` parameter is deprecated and will be removed in 2.0.12 version. Please use `params` to pass this parameter.\n",
      "  'Please use `params` to pass this parameter.', LGBMDeprecationWarning)\n",
      "C:\\Users\\altman\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:642: UserWarning: max_bin keyword has been found in `params` and will be ignored. Please use max_bin argument of the Dataset constructor to pass this parameter.\n",
      "  'Please use {0} argument of the Dataset constructor to pass this parameter.'.format(key))\n",
      "C:\\Users\\altman\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:648: LGBMDeprecationWarning: The `max_bin` parameter is deprecated and will be removed in 2.0.12 version. Please use `params` to pass this parameter.\n",
      "  'Please use `params` to pass this parameter.', LGBMDeprecationWarning)\n",
      "C:\\Users\\altman\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:642: UserWarning: max_bin keyword has been found in `params` and will be ignored. Please use max_bin argument of the Dataset constructor to pass this parameter.\n",
      "  'Please use {0} argument of the Dataset constructor to pass this parameter.'.format(key))\n",
      "C:\\Users\\altman\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:648: LGBMDeprecationWarning: The `max_bin` parameter is deprecated and will be removed in 2.0.12 version. Please use `params` to pass this parameter.\n",
      "  'Please use `params` to pass this parameter.', LGBMDeprecationWarning)\n",
      "C:\\Users\\altman\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:642: UserWarning: max_bin keyword has been found in `params` and will be ignored. Please use max_bin argument of the Dataset constructor to pass this parameter.\n",
      "  'Please use {0} argument of the Dataset constructor to pass this parameter.'.format(key))\n",
      "C:\\Users\\altman\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:648: LGBMDeprecationWarning: The `max_bin` parameter is deprecated and will be removed in 2.0.12 version. Please use `params` to pass this parameter.\n",
      "  'Please use `params` to pass this parameter.', LGBMDeprecationWarning)\n",
      "C:\\Users\\altman\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:642: UserWarning: max_bin keyword has been found in `params` and will be ignored. Please use max_bin argument of the Dataset constructor to pass this parameter.\n",
      "  'Please use {0} argument of the Dataset constructor to pass this parameter.'.format(key))\n",
      "C:\\Users\\altman\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:648: LGBMDeprecationWarning: The `max_bin` parameter is deprecated and will be removed in 2.0.12 version. Please use `params` to pass this parameter.\n",
      "  'Please use `params` to pass this parameter.', LGBMDeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "N = 5\n",
    "kf = KFold(n_splits=N, random_state=42)\n",
    "result_mean = 0.0\n",
    "i = 0\n",
    "test_preds = np.zeros((test_x.shape[0], N))\n",
    "for train_index, test_index in kf.split(train_x):\n",
    "    training_features, training_target = train_x[train_index], train_y[train_index]\n",
    "    testing_features, testing_target = train_x[test_index], train_y[test_index]\n",
    "\n",
    "    exported_pipeline = Pipeline([\n",
    "        (\"scaler\", MaxAbsScaler()),\n",
    "        (\"SVR\", StackingEstimator(estimator=LinearSVR(C=0.01, dual=False, epsilon=1.0, loss=\"squared_epsilon_insensitive\", tol=0.001))),\n",
    "        (\"RidgeCV\", StackingEstimator(estimator=RidgeCV())),\n",
    "        (\"LGB\", lgb.LGBMRegressor(objective='regression',\n",
    "                                  boosting_type=\"GBDT\",\n",
    "                                  num_leaves=17,\n",
    "                                  learning_rate=0.01,\n",
    "                                  feature_fraction=0.5,\n",
    "                                  bagging_fraction=0.5,\n",
    "                                  bagging_freq=5,\n",
    "                                  reg_alpha=0.1,\n",
    "                                  reg_lambda=0.1,\n",
    "                                  n_estimators=400))]\n",
    "    )\n",
    "\n",
    "    exported_pipeline.fit(training_features, training_target)\n",
    "    # 直接加权融合\n",
    "    test_pred = exported_pipeline.predict(test_x)\n",
    "    '''\n",
    "    high_results,pred_high_list,_,_ = modif_value(training_features, training_target, high_labels[train_index], test_x, train_x[np.where(high_labels==-1)[0]],\n",
    "                                                 train_y[np.where(high_labels==-1)[0]])\n",
    "    \n",
    "    if len(high_results) !=0 and len(pred_high_list)!=0:\n",
    "        for ii,jj in enumerate(pred_high_list):\n",
    "            test_pred[jj] = high_results[ii]\n",
    "    for index, value in zip(high_results, pred_high_list):\n",
    "        print(index,value)\n",
    "    #\n",
    "    mystacking = myStackingFeaturesRegressor()\n",
    "    mystacking.fit(training_features, training_target)\n",
    "    new_results = mystacking.predict(test_x)  \n",
    "    test_pred = 0.6*test_pred + 0.4*new_results\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    test_preds[:, i] = test_pred\n",
    "    i += 1\n",
    "results = test_preds.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 0\n",
      "count  1000.000000\n",
      "mean      5.677471\n",
      "std       0.723990\n",
      "min       4.923878\n",
      "25%       5.200138\n",
      "50%       5.465292\n",
      "75%       5.882901\n",
      "max      10.523390\n",
      "             0\n",
      "33    8.524911\n",
      "144   8.104265\n",
      "247   8.887586\n",
      "264   8.056839\n",
      "267   9.450145\n",
      "292   8.542863\n",
      "303   8.795826\n",
      "313   9.824358\n",
      "564   8.174529\n",
      "601   8.061152\n",
      "602   8.176458\n",
      "628   8.407411\n",
      "722   8.135341\n",
      "822   8.474058\n",
      "928   8.934779\n",
      "938  10.523390\n",
      "951   8.333260\n",
      "959   8.023661\n",
      "968   8.539247\n",
      "973   8.453776\n",
      "997   8.357614\n"
     ]
    }
   ],
   "source": [
    "#results[313] = 15.4860937360076\n",
    "#results[938] = 17.5400019823901\n",
    "ouput = pd.DataFrame()\n",
    "ouput[0] = results\n",
    "\n",
    "print(ouput.describe())\n",
    "print(ouput.loc[ouput[0]>8])\n",
    "ouput.to_csv(\"../result/1.18-LiuYuJIA.csv\", header=None, index=False,encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ouput.loc[ouput[0]>6.64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "                 0\n",
    "count  1000.000000\n",
    "mean      5.683937\n",
    "std       0.774499\n",
    "min       4.923878\n",
    "25%       5.200138\n",
    "50%       5.465292\n",
    "75%       5.882901\n",
    "max      14.441510\n",
    "             0\n",
    "267   9.450145\n",
    "313  11.205019\n",
    "928  10.102352\n",
    "938  14.441510"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#not best\n",
    "train = pd.read_csv(\"../data/processed/train.csv\")\n",
    "test = pd.read_csv(\"../data/processed/test.csv\")\n",
    "train.pop(\"id\")\n",
    "test.pop(\"id\")\n",
    "target = train.pop(\"血糖\")\n",
    "\n",
    "train_x= train.as_matrix()\n",
    "train_y = target.as_matrix()\n",
    "test_x = test.as_matrix()\n",
    "exported_pipeline = Pipeline([\n",
    "    (\"scaler\",MaxAbsScaler()),\n",
    "    (\"SVR\",StackingEstimator(estimator=LinearSVR(C=0.01, dual=False, epsilon=1.0, loss=\"squared_epsilon_insensitive\", tol=0.001))),\n",
    "    (\"RidgeCV\",StackingEstimator(estimator=RidgeCV())),\n",
    "    (\"LGB\", lgb.LGBMRegressor(objective='regression',\n",
    "                      boosting_type=\"GBDT\",\n",
    "                      num_leaves=17,\n",
    "                      learning_rate=0.01,\n",
    "                      feature_fraction=0.5,\n",
    "                      bagging_fraction=0.5,\n",
    "                      bagging_freq=5,\n",
    "                      reg_alpha=0.5,\n",
    "                      reg_lambda=0.5,\n",
    "                      n_estimators=400))]\n",
    ")\n",
    "exported_pipeline.fit(train_x, train_y)\n",
    "results_normal = exported_pipeline.predict(test_x)\n",
    "#results_normal[313] = 15.4860937360076\n",
    "#results_normal[938] = 17.5400019823901\n",
    "ouput = pd.DataFrame()\n",
    "ouput[0] = results_normal\n",
    "#ouput.to_csv(\"../result/1.14-LiuYuJia-0.96242-withoutPop-modifyValue.csv\", header=None, index=False,encoding=\"utf-8\")\n",
    "ouput.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\altman\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:642: UserWarning: max_bin keyword has been found in `params` and will be ignored. Please use max_bin argument of the Dataset constructor to pass this parameter.\n",
      "  'Please use {0} argument of the Dataset constructor to pass this parameter.'.format(key))\n",
      "C:\\Users\\altman\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:648: LGBMDeprecationWarning: The `max_bin` parameter is deprecated and will be removed in 2.0.12 version. Please use `params` to pass this parameter.\n",
      "  'Please use `params` to pass this parameter.', LGBMDeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 0\n",
      "count  1000.000000\n",
      "mean      5.676744\n",
      "std       0.757935\n",
      "min       4.892651\n",
      "25%       5.181367\n",
      "50%       5.451028\n",
      "75%       5.881461\n",
      "max      10.797793\n",
      "             0\n",
      "33    9.049166\n",
      "169   8.112911\n",
      "185   8.605971\n",
      "245   8.234955\n",
      "247   9.531291\n",
      "249   8.553951\n",
      "267   9.373990\n",
      "292   8.721753\n",
      "303   8.763350\n",
      "313   9.854436\n",
      "330   8.012021\n",
      "446   8.033770\n",
      "602   8.235244\n",
      "628   8.465243\n",
      "722   8.060280\n",
      "822   8.437048\n",
      "846   8.127580\n",
      "928   9.122541\n",
      "938  10.797793\n",
      "951   8.455134\n",
      "968   8.721563\n",
      "971   8.064821\n",
      "973   8.731417\n",
      "997   8.674035\n"
     ]
    }
   ],
   "source": [
    "#best\n",
    "train = pd.read_csv(\"../data/processed/train_best.csv\")\n",
    "test = pd.read_csv(\"../data/processed/test_best.csv\")\n",
    "train.pop(\"id\")\n",
    "test.pop(\"id\")\n",
    "target = train.pop(\"血糖\")\n",
    "\n",
    "train_x= train.as_matrix()\n",
    "train_y = target.as_matrix()\n",
    "test_x = test.as_matrix()\n",
    "\n",
    "exported_pipeline = make_pipeline(\n",
    "    MaxAbsScaler(),\n",
    "    StackingEstimator(estimator=LinearSVR(C=0.01, dual=False, epsilon=1.0, loss=\"squared_epsilon_insensitive\", tol=0.001)),\n",
    "    StackingEstimator(estimator=RidgeCV()),\n",
    "    lgb.LGBMRegressor(objective='regression',\n",
    "                    boosting_type =\"GBDT\",\n",
    "                    num_leaves=17,\n",
    "                    learning_rate=0.01,\n",
    "                    feature_fraction=0.5,\n",
    "                    bagging_fraction=0.5,\n",
    "                    bagging_freq=5,\n",
    "                    reg_alpha=1,\n",
    "                    reg_lambda=0.5,\n",
    "                    n_estimators=500)\n",
    "    )\n",
    "exported_pipeline.fit(train_x, train_y)\n",
    "results_best = exported_pipeline.predict(test_x)\n",
    "#results_best[313] = 15.4860937360076\n",
    "#results_best[938] = 17.5400019823901\n",
    "ouput = pd.DataFrame()\n",
    "ouput[0] = results_best\n",
    "print(ouput.describe())\n",
    "print(ouput.loc[ouput[0]>8])\n",
    "ouput.to_csv(\"../result/1.16-LiuYuJia-withoutvalue-adddateonehot.csv\", header=None, index=False,encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

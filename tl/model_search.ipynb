{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from util import read_data, save, plt_encoding_error, error, normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../common/data/processed/train.csv\")\n",
    "test_X = pd.read_csv(\"../common/data/processed/test.csv\")\n",
    "test_X.pop(\"id\")\n",
    "test_X = test_X.as_matrix()\n",
    "\n",
    "train.pop(\"id\")\n",
    "target = train.pop(\"血糖\")\n",
    "features = train.columns.tolist()\n",
    "\n",
    "train_X = train.as_matrix()\n",
    "train_Y = target.as_matrix()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# large_list = list()\n",
    "# for i, y in enumerate(train_Y):\n",
    "#     if y > 7:\n",
    "#         large_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "large_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "train_X = PolynomialFeatures().fit_transform(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_X, train_Y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = dict(C=[8, 10, 12, 50],\n",
    "                  epsilon=[0.01,0.02 , 0.04],\n",
    "                  gamma = [0.015, 0.02, 0.03]\n",
    "                  )\n",
    "\n",
    "clf = SVR(C=10, epsilon=0.02)\n",
    "\n",
    "grid = GridSearchCV(cv=5, estimator=clf, n_jobs=-1, param_grid=param_grid, scoring='neg_mean_squared_error')\n",
    "grid.fit(X_train, y_train)\n",
    "print('Best parameters found by grid search are:', grid.best_params_, '  best_score: ', grid.best_score_)\n",
    "y_pred = grid.predict(X_test)\n",
    "# eval\n",
    "error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "clf = SVR(C=10, epsilon=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'boosting': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': 'mse',\n",
    "    'num_leaves': 31,\n",
    "    'min_data_in_leaf': 20,\n",
    "    'learning_rate': 0.02,\n",
    "#     'lambda_l1':1,\n",
    "#     'lambda_l2':0.2,\n",
    "    'cat_smooth':10,\n",
    "    'feature_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbosity':-1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "import lightgbm as lgb\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "X = train_X\n",
    "Y = train_Y\n",
    "N = 5\n",
    "kf = KFold(n_splits=N, shuffle=True, random_state=201801)\n",
    "# kf = KFold(n_splits=N, random_state=42)\n",
    "result_mean = 0.0\n",
    "i = 0\n",
    "test_preds = np.zeros((test_X.shape[0], N))\n",
    "for train_index, test_index in kf.split(X):\n",
    "    training_features, training_target = X[train_index], Y[train_index]\n",
    "    testing_features, testing_target = X[test_index], Y[test_index]\n",
    "    \n",
    "    lgb_train = lgb.Dataset(training_features, training_target)\n",
    "\n",
    "    gbm = lgb.train(params,\n",
    "                    lgb_train,\n",
    "                    num_boost_round=193)\n",
    "\n",
    "    results = gbm.predict(testing_features)\n",
    "    \n",
    "    clf = SVR(C= 12,epsilon = 0.02, gamma=0.015)\n",
    "    clf.fit(training_features, training_target)\n",
    "    results_clf = clf.predict(testing_features)\n",
    "    \n",
    "    test_preds[:, i] = gbm.predict(test_X)\n",
    "    i += 1\n",
    "    aa = (1 * results +0 *results_clf)\n",
    "    result_mean += np.round(mean_squared_error(testing_target, aa), 5)\n",
    "    print(np.round(mean_squared_error(testing_target, aa), 5) / 2)\n",
    "result_mean /= N\n",
    "print(\"Mean squared error: %.5f\" % (result_mean / 2))\n",
    "\n",
    "# submission = pd.DataFrame({'pred':test_preds.mean(axis=1)})\n",
    "# save(submission, 'tpop_kfold_True_201801_96643')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "# create dataset for lightgbm\n",
    "# lgb_train = lgb.Dataset(X_train, y_train, feature_name = features)\n",
    "# lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train, feature_name = features)\n",
    "\n",
    "# train_all = lgb.Dataset(train_X, train_Y, feature_name = features)\n",
    "\n",
    "lgb_train = lgb.Dataset(X_train, y_train)\n",
    "lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)\n",
    "\n",
    "train_all = lgb.Dataset(train_X, train_Y)\n",
    "\n",
    "# specify your configurations as a dict\n",
    "\n",
    "print('Start training...')\n",
    "# train\n",
    "gbm = lgb.train(params,\n",
    "                   lgb_train,\n",
    "                    num_boost_round=283,\n",
    "                    valid_sets=lgb_eval,\n",
    "                    early_stopping_rounds=50)\n",
    "\n",
    "print('Start predicting...')\n",
    "# predict\n",
    "y_pred = gbm.predict(X_test, num_iteration=gbm.best_iteration)\n",
    "# eval\n",
    "error(y_test, y_pred)\n",
    "\n",
    "# online\n",
    "\n",
    "# predict = gbm.predict(test_X, num_iteration=gbm.best_iteration)\n",
    "# data1 = pd.DataFrame(predict)\n",
    "# save\n",
    "# save(data1, 'lgb')\n",
    "\n",
    "# gbm_online = lgb.train(params,\n",
    "#                 train_all,\n",
    "#                 num_boost_round=280)\n",
    "# # predict\n",
    "# predict = gbm_online.predict(test_X, num_iteration=gbm_online.best_iteration)\n",
    "# data1 = pd.DataFrame(predict)\n",
    "# # save\n",
    "# save(data1, 'lgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_encoding_error()\n",
    "lgb.plot_importance(gbm)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
